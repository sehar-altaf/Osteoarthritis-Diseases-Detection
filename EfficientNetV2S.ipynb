{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29c9816-154d-42df-b6d7-2fe85990d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetV2S\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7636e42b-e0b3-497d-8303-ed3b55a1dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\Users\\AI Server1\\Desktop\\Osteoarthritis_sehar\\new_dataset2\"  #0,2,4 classes(healthy,minimal,severe)\n",
    "img_size = (300, 300)\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d834c786-b92b-4e07-90b7-09498b2cd176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3975 images belonging to 3 classes.\n",
      "Found 567 images belonging to 3 classes.\n",
      "Found 1137 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    os.path.join(dataset_path, \"train\"),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    os.path.join(dataset_path, \"val\"),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    os.path.join(dataset_path, \"test\"),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96220cbd-34cc-4090-a013-b061bc922910",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.unique(train_gen.classes)\n",
    "class_weights_dict = dict(zip(class_labels, class_weight.compute_class_weight(class_weight='balanced', classes=class_labels, y=train_gen.classes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6073585-dfe7-4763-8366-466fda5e85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "base_model.trainable = False \n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output = Dense(train_gen.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6),\n",
    "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eecd7a15-b2c8-4417-90ad-06532f1c06bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training top classifier head...\n",
      "Epoch 1/10\n",
      "497/497 [==============================] - 360s 709ms/step - loss: 1.1020 - accuracy: 0.3550 - val_loss: 1.1000 - val_accuracy: 0.1675 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "497/497 [==============================] - 332s 668ms/step - loss: 1.0988 - accuracy: 0.2639 - val_loss: 1.1051 - val_accuracy: 0.1675 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "497/497 [==============================] - 364s 733ms/step - loss: 1.0968 - accuracy: 0.2891 - val_loss: 1.1390 - val_accuracy: 0.1076 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "497/497 [==============================] - 359s 723ms/step - loss: 1.0939 - accuracy: 0.2709 - val_loss: 1.0669 - val_accuracy: 0.5767 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "497/497 [==============================] - 339s 682ms/step - loss: 1.0907 - accuracy: 0.3660 - val_loss: 1.0812 - val_accuracy: 0.2011 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "497/497 [==============================] - 339s 682ms/step - loss: 1.0961 - accuracy: 0.2631 - val_loss: 1.1848 - val_accuracy: 0.1041 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "497/497 [==============================] - 337s 678ms/step - loss: 1.0925 - accuracy: 0.2465 - val_loss: 1.1428 - val_accuracy: 0.1481 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "497/497 [==============================] - 329s 663ms/step - loss: 1.0940 - accuracy: 0.2103 - val_loss: 1.1146 - val_accuracy: 0.1693 - lr: 2.0000e-05\n",
      "Epoch 9/10\n",
      "497/497 [==============================] - 337s 678ms/step - loss: 1.0928 - accuracy: 0.2561 - val_loss: 1.1129 - val_accuracy: 0.1534 - lr: 2.0000e-05\n",
      "Epoch 10/10\n",
      "497/497 [==============================] - 332s 669ms/step - loss: 1.0942 - accuracy: 0.2277 - val_loss: 1.1054 - val_accuracy: 0.1746 - lr: 2.0000e-05\n",
      "Fine-tuning model : \n",
      "Epoch 1/20\n",
      "497/497 [==============================] - 1224s 2s/step - loss: 1.0253 - accuracy: 0.3940 - val_loss: 0.9488 - val_accuracy: 0.5291 - lr: 1.0000e-05\n",
      "Epoch 2/20\n",
      "497/497 [==============================] - 1155s 2s/step - loss: 0.7539 - accuracy: 0.5318 - val_loss: 0.7375 - val_accuracy: 0.6825 - lr: 1.0000e-05\n",
      "Epoch 3/20\n",
      "497/497 [==============================] - 1170s 2s/step - loss: 0.5725 - accuracy: 0.6692 - val_loss: 0.6438 - val_accuracy: 0.7178 - lr: 1.0000e-05\n",
      "Epoch 4/20\n",
      "497/497 [==============================] - 1148s 2s/step - loss: 0.4672 - accuracy: 0.7275 - val_loss: 0.5799 - val_accuracy: 0.7549 - lr: 1.0000e-05\n",
      "Epoch 5/20\n",
      "497/497 [==============================] - 1164s 2s/step - loss: 0.3896 - accuracy: 0.7665 - val_loss: 0.5268 - val_accuracy: 0.7690 - lr: 1.0000e-05\n",
      "Epoch 6/20\n",
      "497/497 [==============================] - 1150s 2s/step - loss: 0.3511 - accuracy: 0.7914 - val_loss: 0.4895 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
      "Epoch 7/20\n",
      "497/497 [==============================] - 1178s 2s/step - loss: 0.3142 - accuracy: 0.8113 - val_loss: 0.4560 - val_accuracy: 0.7813 - lr: 1.0000e-05\n",
      "Epoch 8/20\n",
      "497/497 [==============================] - 1171s 2s/step - loss: 0.3002 - accuracy: 0.8289 - val_loss: 0.4875 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
      "Epoch 9/20\n",
      "497/497 [==============================] - 1167s 2s/step - loss: 0.2697 - accuracy: 0.8372 - val_loss: 0.4641 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
      "Epoch 10/20\n",
      "497/497 [==============================] - 1174s 2s/step - loss: 0.2383 - accuracy: 0.8581 - val_loss: 0.4498 - val_accuracy: 0.7884 - lr: 1.0000e-05\n",
      "Epoch 11/20\n",
      "497/497 [==============================] - 1210s 2s/step - loss: 0.2279 - accuracy: 0.8657 - val_loss: 0.4635 - val_accuracy: 0.7937 - lr: 1.0000e-05\n",
      "Epoch 12/20\n",
      "497/497 [==============================] - 1207s 2s/step - loss: 0.2075 - accuracy: 0.8823 - val_loss: 0.4903 - val_accuracy: 0.8025 - lr: 1.0000e-05\n",
      "Epoch 13/20\n",
      "497/497 [==============================] - 1182s 2s/step - loss: 0.1899 - accuracy: 0.8913 - val_loss: 0.5378 - val_accuracy: 0.7637 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "497/497 [==============================] - 1171s 2s/step - loss: 0.1781 - accuracy: 0.9011 - val_loss: 0.5250 - val_accuracy: 0.7937 - lr: 2.0000e-06\n",
      "Epoch 15/20\n",
      "497/497 [==============================] - 1199s 2s/step - loss: 0.1620 - accuracy: 0.9137 - val_loss: 0.4962 - val_accuracy: 0.7884 - lr: 2.0000e-06\n",
      "Epoch 16/20\n",
      "497/497 [==============================] - 1211s 2s/step - loss: 0.1544 - accuracy: 0.9107 - val_loss: 0.4856 - val_accuracy: 0.7989 - lr: 2.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20414a5cb80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" Training top classifier head...\")\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=10, class_weight=class_weights_dict, callbacks=callbacks)\n",
    "\n",
    "base_model.trainable = True\n",
    "model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Fine-tuning model : \")\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=20, class_weight=class_weights_dict, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7021fc22-cb92-443f-82a8-75e59035cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"EfficientNetV2S.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf0409c-df9d-4482-8b54-9f07566e3f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 79s 553ms/step - loss: 0.3738 - accuracy: 0.8461\n",
      "Final Test Accuracy: 0.8461, Loss: 0.3738\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_gen)\n",
    "print(f\"Final Test Accuracy: {acc:.4f}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b47851-6203-4074-9d3c-c99a883ed705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e4822-5b20-44e0-95ec-35cea7af840e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (S Env)",
   "language": "python",
   "name": "senv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
